{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../tree_rag\")\n",
    "from paper_tree import PaperTree\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_junk(tex):\n",
    "    # Try to get rid of most of the headers\n",
    "    substrings = [\"\\\\maketitle\", \"\\\\end{titlepage}\", \"\\\\end{abstract}\", \"\\\\abstract\"]\n",
    "    max_index = 0\n",
    "    for substring in substrings:\n",
    "        index = tex.rfind(substring)\n",
    "        if index > max_index:\n",
    "            max_index = index\n",
    "    tex = tex[max_index:]\n",
    "\n",
    "    for pattern in [r\"\\\\end\\{titlepage\\}\", r\"\\\\newpage\", r\"\\\\setcounter\", r\"\\\\mbox\", r\"\\\\cleardoublepage\", r\"\\\\pagestyle\\{.*\\}\", r\"\\\\pagenumbering\\{.*\\}\", r\"\\\\bibliographystyle\", r\"\\\\bibliography\\{.*\\}\", r\"\\\\clearpage\", \"\\\\vfill\"]:\n",
    "        tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Find all \\def definitions with or without arguments\n",
    "    pattern = r\"\\\\def\\s*\\\\(\\w+)\\s*((?:#\\d\\s*)*)\\s*({(?:[^{}]*+|(?3))*})\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Find all \\newcommand definitions\n",
    "    pattern = r\"\\\\newcommand\\*?\\s*{?\\s*\\\\(\\w+)\\s*}?\\s*((?:\\[\\s*\\d+\\s*\\])*)\\s*({(?:[^{}]*+|(?3))*})\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Find all \\renewcommand definitions\n",
    "    pattern = r\"\\\\renewcommand\\*?\\s*{?\\s*\\\\(\\w+)\\s*}?\\s*((?:\\[\\s*\\d+\\s*\\])*)\\s*({(?:[^{}]*+|(?3))*})\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Remove all comments\n",
    "    pattern = r\"\\\\begin\\s*\\{\\s*comment\\s*\\}(.*?)\\\\end\\s*\\{\\s*comment\\s*\\}\"\n",
    "    tex = re.sub(pattern, \"\", tex, flags=re.DOTALL)\n",
    "\n",
    "    # Remove all comments\n",
    "    pattern = r\"(?<!\\\\)%.*\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Remove excessive newlines\n",
    "    pattern = r\"\\n\\s+\"\n",
    "    tex = re.sub(pattern, \"\\n\", tex)\n",
    "\n",
    "    # LHCb junk\n",
    "    pattern = r\"\\\\centerline\\s*\\{\\s*\\\\large\\s*\\\\bf\\s*LHCb\\s*collaboration\\s*\\}\\s*\\\\begin\\s*\\{\\s*flushleft\\s*\\}(?:\\n|.)*\\{\\s*\\\\footnotesize(?:\\n|.)*\\}\\s*\\\\end\\s*\\{\\s*flushleft\\s*\\}\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    pattern = r\"\\\\centerline\\s*\\{\\s*\\\\large\\s*\\\\bf\\s*The\\s*LHCb\\s*[Cc]ollaboration\\s*\\}\\s*\\\\begin\\s*\\{\\s*flushleft\\s*\\}(?:\\n|.)*\\\\end\\s*\\{\\s*flushleft\\s*\\}\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    pattern = r\"[a-zA-Z.-]+(?:~[a-zA-Z-\\\\ \\{\\}\\\"\\'\\`]*)+\\$\\^\\{[a-zA-Z0-9,]+\\}\\$[\\,.][\\s\\n]*\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    pattern = r\"(?<=\\n)\\$ \\^{[\\d\\w]+}\\$.*\\n\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    # Get rid of any bibliography\n",
    "    pattern = r\"\\\\bibitem\\{.+\\}(?:.|\\n)*\\\\EndOfBibitem\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    pattern = r\"\\\\begin{thebibliography}(?:\\n|.)*\\\\end{thebibliography}\"\n",
    "    tex = re.sub(pattern, \"\", tex)\n",
    "\n",
    "    return tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_expanded_tex = \"../data/expanded_tex/\"\n",
    "filenames = list(filter(lambda str : (\".tex\" in str[-4:]), os.listdir(dir_expanded_tex)))\n",
    "\n",
    "papers = {}\n",
    "for filename in filenames:\n",
    "    with open(dir_expanded_tex + filename, \"r\") as f:\n",
    "        papers[filename] = clean_junk(f.read())\n",
    "\n",
    "dir_clean_tex = \"../data/clean_tex/\"\n",
    "for id in papers:\n",
    "    paper = papers[id]\n",
    "    with open(dir_clean_tex + id, \"w\") as f:\n",
    "        f.write(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "tokenizer = BertWordPieceTokenizer(lowercase=True)\n",
    "\n",
    "# Train on your corpus\n",
    "expanded_tex = \"../data/clean_tex/\"\n",
    "filenames = [expanded_tex + filename for filename in filter(lambda str : (\".tex\" in str[-4:]), os.listdir(expanded_tex))]\n",
    "tokenizer.train(filenames, vocab_size=30000, min_frequency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertWordPieceTokenizer' object has no attribute 'AutoTokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthellert/physbert_cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertWordPieceTokenizer' object has no attribute 'AutoTokenizer'"
     ]
    }
   ],
   "source": [
    "bert = AutoTokenizer.from_pretrained(\"thellert/physbert_cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  recorded by LHCb \n",
      "at 13\\tev  in 2016--2018 (Run\\,2\\xspace), corresponding to an integrated luminosity of $6 \\invfb$. \n",
      "The \\lhcb detector is a single-arm forward spectrometer covering the {pseudorapidity} range $2<\\eta <5$, described in detail in Refs.~\\cite{LHCb-DP-2008-001,LHCb-DP-2014-002}. \n",
      "The magnetic-field polarity is reversed periodically during data taking to mitigate the differences of reconstruction efficiencies of particles with opposite charges.\n",
      "Data sets corresponding to about half of the total integrated luminosity are recorded with each magnetic-field configuration.\n",
      "Samples of simulated events are used to study the properties of the signal mode\n",
      "$\\decay{\\Bp}\\jpsi{\\decay({}{\\mu^+\\mu^-})\\pip}$ and the control mode $\\decay{\\Bp}\\jpsi{\\decay({}{\\mu^+\\mu^-})\\Kp}$. \n",
      "These simulated events are produced with the software described in Refs.~\\cite{Sjostrand:2007gs, Lange:2001uf,Golonka:2005pn,Allison:2006ve, *Agostinelli:2002hh,LHCb-PROC-2011-006}.\n",
      "The momentum and transverse momentum ($\\pt$) spectra of the \\Bp mesons as well as the track multiplicity in simulation are corrected to match \n",
      "those in data. Additionally, \n",
      "the particle identification (PID) performance of the simulation is also calibrated to match that in data evaluated  with large control samples~\\cite{LHCb-PUB-2016-021,LHCb-DP-2019-001}.\n",
      "The corrections are determined in the initial phase of the analysis and are included in all subsequent steps.\n",
      "The online event selection used in this study is performed by a trigger system ~\\cite{LHCb-DP-2019-001} consisting of a hardware stage that selects events containing at least one muon candidate, and two software trigger stages in which events with two tracks identified as muons with $\\pt >  500 \\mevc$  are selected. The muon pair is required to have an invariant mass within $\\pm150\\mevcc$ of the known \\jpsi mass~\\cite{PDG2024}.\n",
      "In the offline selection, the $\\decay{\\Bp}{\\jpsi h^+}$  candidates (where $h=\\pi, K$) are formed by combining a \\jpsi with a hadron candidate with $\\pt$ above $1\\gevc$. \n",
      "The selection criteria for the \\Bpi and \\Bk decays are  similar except those related to the identification of the kaon and pion hadrons in the final states.\n",
      "The accompanying hadron is mutually exclusively \n",
      "identified  as a pion or kaon using information from the ring-imaging Cherenkov detectors~\\cite{LHCb-DP-2012-003}, and required to be inconsistent with originating from any primary  $pp$ collision  vertex (PV) and  consistent with originating \n",
      "from the \\jpsi decay vertex.\n",
      "The particle identification criteria \n",
      "achieve a signal efficiency of \n",
      "$96\\%$ ($92\\%$) for the  $\\Bpi$ ($\\Bk$)  decay, while rejecting\n",
      "$97\\%$ ($99\\%$) of the misidentified cross-feed background coming from the $\\Bk$ ($\\Bpi$) decay. \n",
      "Each \\Bp candidate must be consistent with originating from a PV.  \n",
      "A kinematic fit~\\cite{Hulsbergen:2005pu} to the signal decay,\n",
      "where the \\jpsi mass is constrained to its \n",
      "known value~\\cite{PDG2024}, is performed \n",
      "to achieve a better \n",
      "resolution of the reconstructed $B$ mass.\n",
      "The remaining \\Bp candidates with $\\cos\\theta_h<0$ are rejected to ensure a clear separation of the \\Bpi and \\Bk mass peaks in the \\jpsi\\pip mass spectrum, where $\\theta_h$ is the  angle between  the momentum of the accompanying hadron in the \\Bp rest frame and the \\Bp momentum in the laboratory frame.\n",
      "Fiducial-volume requirements are also imposed to exclude those \\Bp candidates with accompanying hadrons at the boundaries of the detector acceptance, where\n",
      "the detection asymmetry is particularly large. Such requirements retain more than $95\\%$ of the $\\decay{\\Bp}{\\jpsi h^+}$ signals. \n",
      "In order to further suppress the background from random combinations of tracks~(combinatorial background), a boosted decision tree  (BDT) classifier~\\cite{Breiman,Hocker:2007ht}\n",
      "is trained  for each of  the \\Bpi and \\Bk decay modes and each year of data taking.  The BDT classifier is trained using  simulated $\\decay{\\Bp}{\\jpsi h^+}$  decays as a signal proxy\n",
      "and a \n",
      "sample of data candidates in the upper mass sideband [5500, 5700] \\mevcc \n",
      "above the fit range as a background proxy.\n",
      "The kinematic and geometrical variables  used as inputs to the BDT classifier include:\n",
      "measures of the likelihood \n",
      "that the $h^+$, $\\mu^\\pm$, \\jpsi or \\Bp candidate comes from the PV;\n",
      "transverse momentum\n",
      "of the $h^+$, \\jpsi and \\Bp candidates; \n",
      "flight distance and vertex fit quality of the \\Bp candidate.\n",
      "The $B^+$ candidates with a BDT response below a certain threshold are rejected. This threshold for the \\Bpi mode is chosen to optimize the signal significance. \n",
      "For \\Bk decays, the threshold  is chosen to obtain the same BDT selection efficiency as  that for the \\Bpi mode.\n",
      "The optimized BDT selection retains about $95\\%$ of both signals, while rejecting more than $90\\%$ of the combinatorial backgrounds.\n",
      "An unbinned extended maximum-likelihood fit is performed simultaneously  to the mass distributions of the selected \\Bp and \\Bm candidates in the  mass range [5050, 5500]~\\mevcc, \n",
      "f\n"
     ]
    }
   ],
   "source": [
    "chunk = papers[\"2411.12178.tex\"][5000:10000]\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'recorded',\n",
       " 'by',\n",
       " 'lhcb',\n",
       " 'at',\n",
       " '13',\n",
       " '\\\\',\n",
       " 'tev',\n",
       " 'in',\n",
       " '2016',\n",
       " '-',\n",
       " '-',\n",
       " '2018',\n",
       " '(',\n",
       " 'run',\n",
       " '\\\\',\n",
       " ',',\n",
       " '2',\n",
       " '\\\\',\n",
       " 'xspace',\n",
       " ')',\n",
       " ',',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " 'an',\n",
       " 'integrated',\n",
       " 'luminosity',\n",
       " 'of',\n",
       " '$',\n",
       " '6',\n",
       " '\\\\',\n",
       " 'invfb',\n",
       " '$',\n",
       " '.',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'lhcb',\n",
       " 'detector',\n",
       " 'is',\n",
       " 'a',\n",
       " 'single',\n",
       " '-',\n",
       " 'arm',\n",
       " 'forward',\n",
       " 'spectrometer',\n",
       " 'covering',\n",
       " 'the',\n",
       " '{',\n",
       " 'pseudorapidity',\n",
       " '}',\n",
       " 'range',\n",
       " '$',\n",
       " '2',\n",
       " '<',\n",
       " '\\\\',\n",
       " 'eta',\n",
       " '<',\n",
       " '5',\n",
       " '$',\n",
       " ',',\n",
       " 'described',\n",
       " 'in',\n",
       " 'detail',\n",
       " 'in',\n",
       " 'refs',\n",
       " '.',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'dp',\n",
       " '-',\n",
       " '2008',\n",
       " '-',\n",
       " '001',\n",
       " ',',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'dp',\n",
       " '-',\n",
       " '2014',\n",
       " '-',\n",
       " '002',\n",
       " '}',\n",
       " '.',\n",
       " 'the',\n",
       " 'magnetic',\n",
       " '-',\n",
       " 'field',\n",
       " 'polarity',\n",
       " 'is',\n",
       " 'reversed',\n",
       " 'periodically',\n",
       " 'during',\n",
       " 'data',\n",
       " 'taking',\n",
       " 'to',\n",
       " 'mitigate',\n",
       " 'the',\n",
       " 'differences',\n",
       " 'of',\n",
       " 'reconstruction',\n",
       " 'efficiencies',\n",
       " 'of',\n",
       " 'particles',\n",
       " 'with',\n",
       " 'opposite',\n",
       " 'charges',\n",
       " '.',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " 'about',\n",
       " 'half',\n",
       " 'of',\n",
       " 'the',\n",
       " 'total',\n",
       " 'integrated',\n",
       " 'luminosity',\n",
       " 'are',\n",
       " 'recorded',\n",
       " 'with',\n",
       " 'each',\n",
       " 'magnetic',\n",
       " '-',\n",
       " 'field',\n",
       " 'configuration',\n",
       " '.',\n",
       " 'samples',\n",
       " 'of',\n",
       " 'simulated',\n",
       " 'events',\n",
       " 'are',\n",
       " 'used',\n",
       " 'to',\n",
       " 'study',\n",
       " 'the',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'the',\n",
       " 'signal',\n",
       " 'mode',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " '}',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '(',\n",
       " '{',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'mu',\n",
       " '^',\n",
       " '+',\n",
       " '\\\\',\n",
       " 'mu',\n",
       " '^',\n",
       " '-',\n",
       " '}',\n",
       " ')',\n",
       " '\\\\',\n",
       " 'pip',\n",
       " '}',\n",
       " '$',\n",
       " 'and',\n",
       " 'the',\n",
       " 'control',\n",
       " 'mode',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " '}',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '(',\n",
       " '{',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'mu',\n",
       " '^',\n",
       " '+',\n",
       " '\\\\',\n",
       " 'mu',\n",
       " '^',\n",
       " '-',\n",
       " '}',\n",
       " ')',\n",
       " '\\\\',\n",
       " 'kp',\n",
       " '}',\n",
       " '$',\n",
       " '.',\n",
       " 'these',\n",
       " 'simulated',\n",
       " 'events',\n",
       " 'are',\n",
       " 'produced',\n",
       " 'with',\n",
       " 'the',\n",
       " 'software',\n",
       " 'described',\n",
       " 'in',\n",
       " 'refs',\n",
       " '.',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'sjostrand',\n",
       " ':',\n",
       " '2007gs',\n",
       " ',',\n",
       " 'lange',\n",
       " ':',\n",
       " '2001uf',\n",
       " ',',\n",
       " 'golonka',\n",
       " ':',\n",
       " '2005pn',\n",
       " ',',\n",
       " 'allison',\n",
       " ':',\n",
       " '2006ve',\n",
       " ',',\n",
       " '*',\n",
       " 'agostinelli',\n",
       " ':',\n",
       " '2002hh',\n",
       " ',',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'proc',\n",
       " '-',\n",
       " '2011',\n",
       " '-',\n",
       " '006',\n",
       " '}',\n",
       " '.',\n",
       " 'the',\n",
       " 'momentum',\n",
       " 'and',\n",
       " 'transverse',\n",
       " 'momentum',\n",
       " '(',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'pt',\n",
       " '$',\n",
       " ')',\n",
       " 'spectra',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'mesons',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'track',\n",
       " 'multiplicity',\n",
       " 'in',\n",
       " 'simulation',\n",
       " 'are',\n",
       " 'corrected',\n",
       " 'to',\n",
       " 'match',\n",
       " 'those',\n",
       " 'in',\n",
       " 'data',\n",
       " '.',\n",
       " 'additionally',\n",
       " ',',\n",
       " 'the',\n",
       " 'particle',\n",
       " 'identification',\n",
       " '(',\n",
       " 'pid',\n",
       " ')',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'is',\n",
       " 'also',\n",
       " 'calibrated',\n",
       " 'to',\n",
       " 'match',\n",
       " 'that',\n",
       " 'in',\n",
       " 'data',\n",
       " 'evaluated',\n",
       " 'with',\n",
       " 'large',\n",
       " 'control',\n",
       " 'samples',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'pub',\n",
       " '-',\n",
       " '2016',\n",
       " '-',\n",
       " '021',\n",
       " ',',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'dp',\n",
       " '-',\n",
       " '2019',\n",
       " '-',\n",
       " '001',\n",
       " '}',\n",
       " '.',\n",
       " 'the',\n",
       " 'corrections',\n",
       " 'are',\n",
       " 'determined',\n",
       " 'in',\n",
       " 'the',\n",
       " 'initial',\n",
       " 'phase',\n",
       " 'of',\n",
       " 'the',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'are',\n",
       " 'included',\n",
       " 'in',\n",
       " 'all',\n",
       " 'subsequent',\n",
       " 'steps',\n",
       " '.',\n",
       " 'the',\n",
       " 'online',\n",
       " 'event',\n",
       " 'selection',\n",
       " 'used',\n",
       " 'in',\n",
       " 'this',\n",
       " 'study',\n",
       " 'is',\n",
       " 'performed',\n",
       " 'by',\n",
       " 'a',\n",
       " 'trigger',\n",
       " 'system',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'dp',\n",
       " '-',\n",
       " '2019',\n",
       " '-',\n",
       " '001',\n",
       " '}',\n",
       " 'consisting',\n",
       " 'of',\n",
       " 'a',\n",
       " 'hardware',\n",
       " 'stage',\n",
       " 'that',\n",
       " 'selects',\n",
       " 'events',\n",
       " 'containing',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'muon',\n",
       " 'candidate',\n",
       " ',',\n",
       " 'and',\n",
       " 'two',\n",
       " 'software',\n",
       " 'trigger',\n",
       " 'stages',\n",
       " 'in',\n",
       " 'which',\n",
       " 'events',\n",
       " 'with',\n",
       " 'two',\n",
       " 'tracks',\n",
       " 'identified',\n",
       " 'as',\n",
       " 'muons',\n",
       " 'with',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'pt',\n",
       " '>',\n",
       " '500',\n",
       " '\\\\',\n",
       " 'mevc',\n",
       " '$',\n",
       " 'are',\n",
       " 'selected',\n",
       " '.',\n",
       " 'the',\n",
       " 'muon',\n",
       " 'pair',\n",
       " 'is',\n",
       " 'required',\n",
       " 'to',\n",
       " 'have',\n",
       " 'an',\n",
       " 'invariant',\n",
       " 'mass',\n",
       " 'within',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'pm150',\n",
       " '\\\\',\n",
       " 'mevcc',\n",
       " '$',\n",
       " 'of',\n",
       " 'the',\n",
       " 'known',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'mass',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'pdg2024',\n",
       " '}',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'offline',\n",
       " 'selection',\n",
       " ',',\n",
       " 'the',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'h',\n",
       " '^',\n",
       " '+',\n",
       " '}',\n",
       " '$',\n",
       " 'candidates',\n",
       " '(',\n",
       " 'where',\n",
       " '$',\n",
       " 'h',\n",
       " '=',\n",
       " '\\\\',\n",
       " 'pi',\n",
       " ',',\n",
       " 'k',\n",
       " '$',\n",
       " ')',\n",
       " 'are',\n",
       " 'formed',\n",
       " 'by',\n",
       " 'combining',\n",
       " 'a',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'with',\n",
       " 'a',\n",
       " 'hadron',\n",
       " 'candidate',\n",
       " 'with',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'pt',\n",
       " '$',\n",
       " 'above',\n",
       " '$',\n",
       " '1',\n",
       " '\\\\',\n",
       " 'gevc',\n",
       " '$',\n",
       " '.',\n",
       " 'the',\n",
       " 'selection',\n",
       " 'criteria',\n",
       " 'for',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bpi',\n",
       " 'and',\n",
       " '\\\\',\n",
       " 'bk',\n",
       " 'decays',\n",
       " 'are',\n",
       " 'similar',\n",
       " 'except',\n",
       " 'those',\n",
       " 'related',\n",
       " 'to',\n",
       " 'the',\n",
       " 'identification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'kaon',\n",
       " 'and',\n",
       " 'pion',\n",
       " 'hadrons',\n",
       " 'in',\n",
       " 'the',\n",
       " 'final',\n",
       " 'states',\n",
       " '.',\n",
       " 'the',\n",
       " 'accompanying',\n",
       " 'hadron',\n",
       " 'is',\n",
       " 'mutually',\n",
       " 'exclusively',\n",
       " 'identified',\n",
       " 'as',\n",
       " 'a',\n",
       " 'pion',\n",
       " 'or',\n",
       " 'kaon',\n",
       " 'using',\n",
       " 'information',\n",
       " 'from',\n",
       " 'the',\n",
       " 'ring',\n",
       " '-',\n",
       " 'imaging',\n",
       " 'cherenkov',\n",
       " 'detectors',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'lhcb',\n",
       " '-',\n",
       " 'dp',\n",
       " '-',\n",
       " '2012',\n",
       " '-',\n",
       " '003',\n",
       " '}',\n",
       " ',',\n",
       " 'and',\n",
       " 'required',\n",
       " 'to',\n",
       " 'be',\n",
       " 'inconsistent',\n",
       " 'with',\n",
       " 'originating',\n",
       " 'from',\n",
       " 'any',\n",
       " 'primary',\n",
       " '$',\n",
       " 'pp',\n",
       " '$',\n",
       " 'collision',\n",
       " 'vertex',\n",
       " '(',\n",
       " 'pv',\n",
       " ')',\n",
       " 'and',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'originating',\n",
       " 'from',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'decay',\n",
       " 'vertex',\n",
       " '.',\n",
       " 'the',\n",
       " 'particle',\n",
       " 'identification',\n",
       " 'criteria',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'signal',\n",
       " 'efficiency',\n",
       " 'of',\n",
       " '$',\n",
       " '96',\n",
       " '\\\\',\n",
       " '%',\n",
       " '$',\n",
       " '(',\n",
       " '$',\n",
       " '92',\n",
       " '\\\\',\n",
       " '%',\n",
       " '$',\n",
       " ')',\n",
       " 'for',\n",
       " 'the',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'bpi',\n",
       " '$',\n",
       " '(',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'bk',\n",
       " '$',\n",
       " ')',\n",
       " 'decay',\n",
       " ',',\n",
       " 'while',\n",
       " 'rejecting',\n",
       " '$',\n",
       " '97',\n",
       " '\\\\',\n",
       " '%',\n",
       " '$',\n",
       " '(',\n",
       " '$',\n",
       " '99',\n",
       " '\\\\',\n",
       " '%',\n",
       " '$',\n",
       " ')',\n",
       " 'of',\n",
       " 'the',\n",
       " 'misidentified',\n",
       " 'cross',\n",
       " '-',\n",
       " 'feed',\n",
       " 'background',\n",
       " 'coming',\n",
       " 'from',\n",
       " 'the',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'bk',\n",
       " '$',\n",
       " '(',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'bpi',\n",
       " '$',\n",
       " ')',\n",
       " 'decay',\n",
       " '.',\n",
       " 'each',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'candidate',\n",
       " 'must',\n",
       " 'be',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'originating',\n",
       " 'from',\n",
       " 'a',\n",
       " 'pv',\n",
       " '.',\n",
       " 'a',\n",
       " 'kinematic',\n",
       " 'fit',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'hulsbergen',\n",
       " ':',\n",
       " '2005pu',\n",
       " '}',\n",
       " 'to',\n",
       " 'the',\n",
       " 'signal',\n",
       " 'decay',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'mass',\n",
       " 'is',\n",
       " 'constrained',\n",
       " 'to',\n",
       " 'its',\n",
       " 'known',\n",
       " 'value',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'pdg2024',\n",
       " '}',\n",
       " ',',\n",
       " 'is',\n",
       " 'performed',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'better',\n",
       " 'resolution',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reconstructed',\n",
       " '$',\n",
       " 'b',\n",
       " '$',\n",
       " 'mass',\n",
       " '.',\n",
       " 'the',\n",
       " 'remaining',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'candidates',\n",
       " 'with',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'cos',\n",
       " '\\\\',\n",
       " 'theta',\n",
       " '_',\n",
       " 'h',\n",
       " '<',\n",
       " '0',\n",
       " '$',\n",
       " 'are',\n",
       " 'rejected',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'a',\n",
       " 'clear',\n",
       " 'separation',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bpi',\n",
       " 'and',\n",
       " '\\\\',\n",
       " 'bk',\n",
       " 'mass',\n",
       " 'peaks',\n",
       " 'in',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " '\\\\',\n",
       " 'pip',\n",
       " 'mass',\n",
       " 'spectrum',\n",
       " ',',\n",
       " 'where',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'theta',\n",
       " '_',\n",
       " 'h',\n",
       " '$',\n",
       " 'is',\n",
       " 'the',\n",
       " 'angle',\n",
       " 'between',\n",
       " 'the',\n",
       " 'momentum',\n",
       " 'of',\n",
       " 'the',\n",
       " 'accompanying',\n",
       " 'hadron',\n",
       " 'in',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'rest',\n",
       " 'frame',\n",
       " 'and',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'momentum',\n",
       " 'in',\n",
       " 'the',\n",
       " 'laboratory',\n",
       " 'frame',\n",
       " '.',\n",
       " 'fiducial',\n",
       " '-',\n",
       " 'volume',\n",
       " 'requirements',\n",
       " 'are',\n",
       " 'also',\n",
       " 'imposed',\n",
       " 'to',\n",
       " 'exclude',\n",
       " 'those',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " 'candidates',\n",
       " 'with',\n",
       " 'accompanying',\n",
       " 'hadrons',\n",
       " 'at',\n",
       " 'the',\n",
       " 'boundaries',\n",
       " 'of',\n",
       " 'the',\n",
       " 'detector',\n",
       " 'acceptance',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " 'detection',\n",
       " 'asymmetry',\n",
       " 'is',\n",
       " 'particularly',\n",
       " 'large',\n",
       " '.',\n",
       " 'such',\n",
       " 'requirements',\n",
       " 'retain',\n",
       " 'more',\n",
       " 'than',\n",
       " '$',\n",
       " '95',\n",
       " '\\\\',\n",
       " '%',\n",
       " '$',\n",
       " 'of',\n",
       " 'the',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'h',\n",
       " '^',\n",
       " '+',\n",
       " '}',\n",
       " '$',\n",
       " 'signals',\n",
       " '.',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'further',\n",
       " 'suppress',\n",
       " 'the',\n",
       " 'background',\n",
       " 'from',\n",
       " 'random',\n",
       " 'combinations',\n",
       " 'of',\n",
       " 'tracks',\n",
       " '~',\n",
       " '(',\n",
       " 'combinatorial',\n",
       " 'background',\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'boosted',\n",
       " 'decision',\n",
       " 'tree',\n",
       " '(',\n",
       " 'bdt',\n",
       " ')',\n",
       " 'classifier',\n",
       " '~',\n",
       " '\\\\',\n",
       " 'cite',\n",
       " '{',\n",
       " 'breiman',\n",
       " ',',\n",
       " 'hocker',\n",
       " ':',\n",
       " '2007ht',\n",
       " '}',\n",
       " 'is',\n",
       " 'trained',\n",
       " 'for',\n",
       " 'each',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\\\',\n",
       " 'bpi',\n",
       " 'and',\n",
       " '\\\\',\n",
       " 'bk',\n",
       " 'decay',\n",
       " 'modes',\n",
       " 'and',\n",
       " 'each',\n",
       " 'year',\n",
       " 'of',\n",
       " 'data',\n",
       " 'taking',\n",
       " '.',\n",
       " 'the',\n",
       " 'bdt',\n",
       " 'classifier',\n",
       " 'is',\n",
       " 'trained',\n",
       " 'using',\n",
       " 'simulated',\n",
       " '$',\n",
       " '\\\\',\n",
       " 'decay',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'bp',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " 'jpsi',\n",
       " 'h',\n",
       " '^',\n",
       " '+',\n",
       " '}',\n",
       " '$',\n",
       " 'decays',\n",
       " 'as',\n",
       " 'a',\n",
       " 'signal',\n",
       " 'proxy',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'of',\n",
       " 'data',\n",
       " 'candidates',\n",
       " 'in',\n",
       " 'the',\n",
       " 'upper',\n",
       " 'mass',\n",
       " 'sideband',\n",
       " '[',\n",
       " '5500',\n",
       " ',',\n",
       " '5700',\n",
       " ']',\n",
       " '\\\\',\n",
       " 'mevcc',\n",
       " 'above',\n",
       " 'the',\n",
       " 'fit',\n",
       " 'range',\n",
       " 'as',\n",
       " 'a',\n",
       " 'background',\n",
       " 'proxy',\n",
       " '.',\n",
       " 'the',\n",
       " 'kinematic',\n",
       " 'and',\n",
       " 'geometrical',\n",
       " 'variables',\n",
       " 'used',\n",
       " 'as',\n",
       " 'inputs',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bdt',\n",
       " 'classifier',\n",
       " 'include',\n",
       " ':',\n",
       " 'measures',\n",
       " 'of',\n",
       " 'the',\n",
       " 'likelihood',\n",
       " 'that',\n",
       " 'the',\n",
       " '$',\n",
       " 'h',\n",
       " ...]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(chunk).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beauty-in-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
