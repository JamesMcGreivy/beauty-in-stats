{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Paper Trees from Raw LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "import paper_tree\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import importlib\n",
    "importlib.reload(paper_tree)\n",
    "\n",
    "dir_expanded_tex = \"../data/expanded_tex/\"\n",
    "dir_abstracts = \"../data/abstracts/\"\n",
    "dir_paper_trees = \"./saved_paper_trees/paper_trees/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 781/781 [00:21<00:00, 35.62it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(dir_paper_trees, exist_ok=True)\n",
    "def tex_to_paper_tree(filename):\n",
    "    with open(dir_abstracts + filename) as file:\n",
    "        abstract = file.read()\n",
    "    with open(dir_expanded_tex + filename) as file:\n",
    "        full_tex = file.read()\n",
    "    full_tex = paper_tree.clean_junk(full_tex)\n",
    "    # Build the Paper Tree object\n",
    "    paper = paper_tree.PaperTree(filename, full_tex, abstract = abstract, section_max_tokens = 500)\n",
    "    # Clean up all empty sections, expand subsections if the paper is in 'Letter' format\n",
    "    paper_tree.remove_empty_sections(paper)\n",
    "    paper_tree.fix_letter_subsections(paper)\n",
    "    paper_tree.collapse_lone_subsections(paper)\n",
    "    return paper\n",
    "\n",
    "filenames = list(filter(lambda str : (\".tex\" in str[-4:]), os.listdir(dir_expanded_tex)))\n",
    "\n",
    "papers = []\n",
    "with ThreadPoolExecutor(max_workers = 20) as executor:\n",
    "    futures = [executor.submit(tex_to_paper_tree, filename) for filename in filenames]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "        paper = future.result()\n",
    "        papers.append(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some elements do not have easily parsed captions, need to manually find them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_caption = []\n",
    "\n",
    "def build_no_caption(paper, no_caption):\n",
    "    for section in paper.sections:\n",
    "        build_no_caption(section, no_caption)\n",
    "    if paper.abstract is not None:\n",
    "        if any([e in paper.title for e in [\"figure\", \"table\", \"sidewaystable\"]]):\n",
    "            if len(paper.abstract) < 10:\n",
    "                no_caption.append(paper)\n",
    "\n",
    "for paper in papers:\n",
    "    build_no_caption(paper, no_caption)\n",
    "\n",
    "len(no_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Element:  1707.01665.tex --> Appendix --> Fit results by category --> table 0\n",
      "Element Text:  [htb] \\paperCaption{2011} \\begin{center} \\begin{tabular}{l | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} } & \\multicolumn{4}{c|}{\\DD} & \\multicolumn{4}{c}{\\LL} \\\\ Decay & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c|}{Efficiency (\\%)} & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c}{Efficiency (\\%)} \\\\ \\hline \\BdtoKsPiPi & $803$ & $36$ & $0.0488$ & $0.0093$ & $471$ & $27$ & $0.0188$ & $0.0036$ \\\\ \\BdtoKsKK & $281$ & $19$ & $0.0292$ & $0.0063$ & $222$ & $17$ & $0.0157$ & $0.0034$ \\\\ \\BstoKsKPi & $333$ & $23$ & $0.0361$ & $0.0064$ & $207$ & $16$ & $0.0148$ & $0.0025$ \\\\ \\BdtoKsKPi & $76$ & $13$ & $0.0322$ & $0.0063$ & $50$ & $9$ & $0.0174$ & $0.0034$ \\\\ \\BstoKsPiPi & $43$ & $10$ & $0.0316$ & $0.0051$ & $21$ & $8$ & $0.0160$ & $0.0025$ \\\\ \\BstoKsKK & $5$ & $3$ & $0.0244$ & $0.0052$ & $4$ & $3$ & $0.0129$ & $0.0029$ \\\\ \\end{tabular} \\end{center}\n",
      "\n",
      "Current Caption:  \n",
      "For Element:  1707.01665.tex --> Appendix --> Fit results by category --> table 1\n",
      "Element Text:  [htb] \\paperCaption{2012a} \\begin{center} \\begin{tabular}{l | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} } & \\multicolumn{4}{c|}{\\DD} & \\multicolumn{4}{c}{\\LL} \\\\ Decay & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c|}{Efficiency (\\%)} & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c}{Efficiency (\\%)} \\\\ \\hline \\BdtoKsPiPi & $553$ & $30$ & $0.0423$ & $0.0059$ & $286$ & $20$ & $0.0166$ & $0.0023$ \\\\ \\BdtoKsKK & $181$ & $15$ & $0.0263$ & $0.0052$ & $119$ & $12$ & $0.0149$ & $0.0029$ \\\\ \\BstoKsKPi & $205$ & $18$ & $0.0395$ & $0.0060$ & $99$ & $13$ & $0.0155$ & $0.0023$ \\\\ \\BdtoKsKPi & $63$ & $11$ & $0.0306$ & $0.0047$ & $45$ & $10$ & $0.0143$ & $0.0022$ \\\\ \\BstoKsPiPi & $17$ & $8$ & $0.0493$ & $0.0068$ & $15$ & $6$ & $0.0145$ & $0.0021$ \\\\ \\BstoKsKK & $2$ & $3$ & $0.0290$ & $0.0039$ & $1$ & $2$ & $0.0092$ & $0.0030$ \\\\ \\end{tabular} \\end{center}\n",
      "\n",
      "Current Caption:  \n",
      "For Element:  1707.01665.tex --> Appendix --> Fit results by category --> table 2\n",
      "Element Text:  [htb] \\paperCaption{2012b} \\begin{center} \\begin{tabular}{l | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} | >{\\hfill} p{0.9cm}@{$\\,\\pm\\,$}p{0.5cm} >{\\hfill} p{1.25cm}@{$\\,\\pm\\,$}p{1.25cm} } & \\multicolumn{4}{c|}{\\DD} & \\multicolumn{4}{c}{\\LL} \\\\ Decay & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c|}{Efficiency (\\%)} & \\multicolumn{2}{c}{Yield} & \\multicolumn{2}{c}{Efficiency (\\%)} \\\\ \\hline \\BdtoKsPiPi & $1410$ & $46$ & $0.0455$ & $0.0063$ & $654$ & $30$ & $0.0161$ & $0.0022$ \\\\ \\BdtoKsKK & $671$ & $30$ & $0.0395$ & $0.0076$ & $344$ & $20$ & $0.0128$ & $0.0025$ \\\\ \\BstoKsKPi & $562$ & $29$ & $0.0401$ & $0.0059$ & $262$ & $19$ & $0.0138$ & $0.0020$ \\\\ \\BdtoKsKPi & $122$ & $17$ & $0.0402$ & $0.0056$ & $65$ & $10$ & $0.0100$ & $0.0015$ \\\\ \\BstoKsPiPi & $86$ & $14$ & $0.0335$ & $0.0045$ & $38$ & $5$ & $0.0108$ & $0.0015$ \\\\ \\BstoKsKK & $5$ & $4$ & $0.0291$ & $0.0034$ & $2$ & $2$ & $0.0083$ & $0.0017$ \\\\ \\end{tabular} \\end{center}\n",
      "\n",
      "Current Caption:  \n"
     ]
    }
   ],
   "source": [
    "# FOR \\paperCaption{YEAR}:\n",
    "\"\"\"\n",
    "Signal yields obtained for the 2012b category from the\n",
    "simultaneous fit to the data.\n",
    "The yields shown are those obtained when fitting the data sample\n",
    "selected using the BDT optimisation chosen for the given decay mode.\n",
    "The uncertainties are statistical only.\n",
    "The average selection efficiencies, described in\n",
    "Sec.~\\ref{sec:Efficiencies}, are also shown for each decay mode\n",
    "together with the corresponding total uncertainty due to the limited\n",
    "simulation sample size and systematic effects in their determination.\n",
    "\"\"\"\n",
    "\n",
    "# FOR \\resultstable:\n",
    "\"\"\"\n",
    "Summary of $P_c^+$ properties. The central values are based on the fit displayed in Fig.~\\ref{fig:defaultFit}.\n",
    "\"\"\"\n",
    "\n",
    "for element in no_caption:\n",
    "    id = element.title\n",
    "    parent = element.parent\n",
    "    while parent is not None:\n",
    "        id = f\"{parent.title} --> {id}\"\n",
    "        parent = parent.parent\n",
    "    print(\"For Element: \", id)\n",
    "    print(\"Element Text: \", element.text)\n",
    "    print(\"Current Caption: \", element.abstract)\n",
    "    caption = input(f\"Please manually enter the caption. Enter CANCEL to skip manually finding captions.\")\n",
    "    if caption.lower() == \"cancel\":\n",
    "        break\n",
    "    element.abstract = caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE ALL PAPER TREES\n",
    "os.makedirs(dir_paper_trees, exist_ok = True)\n",
    "for paper in papers:\n",
    "    with open(dir_paper_trees + paper.title[:-4] + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(paper, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-level Abstract Generation with Summarization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "import paper_tree\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import importlib\n",
    "importlib.reload(paper_tree)\n",
    "dir_expanded_tex = \"../data/expanded_tex/\"\n",
    "dir_abstracts = \"../data/abstracts/\"\n",
    "dir_paper_trees = \"./saved_paper_trees/paper_trees/\"\n",
    "\n",
    "# Directory to write sumarized paper trees\n",
    "dir_summarized_paper_trees = \"./saved_paper_trees/summarized_openai_paper_trees/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load paper trees to be summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = dir_summarized_paper_trees\n",
    "\n",
    "# LOAD ALL PAPER TREES\n",
    "filenames = list(filter(lambda str : (\".pkl\" in str[-4:]), os.listdir(load_dir)))\n",
    "papers = []\n",
    "for filename in filenames:\n",
    "    with open(load_dir + filename, \"rb\") as f:\n",
    "        paper = pickle.load(f)\n",
    "        papers.append(paper)\n",
    "\n",
    "# For any section with no children, the abstract is just equal to the text\n",
    "def give_abstract(paper):\n",
    "    if paper.abstract is None and len(paper.sections) == 0:\n",
    "        paper.abstract = paper.text\n",
    "    for section in paper.sections:\n",
    "        give_abstract(section)\n",
    "for paper in papers:\n",
    "    give_abstract(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Summarize with ChatGPT 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "def get_prompt(excerpt):\n",
    "    prompt = f\"\"\"\n",
    "    Instruction:\n",
    "    You are an expert in particle physics and machine learning. Your task is to give a 400-token summary of the following excerpt, preserving all key details that would be needed for using this summary for cosine-similarity search with sentence embeddings.\n",
    "\n",
    "    ### Guidelines:\n",
    "    Exclude Redundant Content - Do not include background information about the LHC or LHCb detector, citations, or general particle physics knowledge.\n",
    "    Preserve Important Information - Retain experimental results, theoretical conclusions, and key terminology (e.g., particle names, detector specifics, statistical methods).\n",
    "    Describe all formulas in words - Avoid including raw mathematical expressions, as they cannot be effectively indexed by a RAG system. Instead, provide a clear verbal explanation of a formula's significance in the context of the excerpt.\n",
    "    Maintain Technical Precision - Avoid oversimplification of physics concepts; the summary should be useful for physicists querying a RAG system.\n",
    "    Format Clearly - Use concise technical language, structured paragraphs, and bullet points if necessary for clarity.\n",
    "    400 Tokens Max - Ensure the output remains under 400 tokens while fully capturing the core findings of the text.\n",
    "\n",
    "    ### Paper Excerpt:\n",
    "    {excerpt}\n",
    "\n",
    "    Output the summary below.\n",
    "    \"\"\"\n",
    "    return prompt       \n",
    "\n",
    "async def summarize(paper):\n",
    "    text = \"\"\n",
    "    for section in paper.sections:\n",
    "        elements = [\"figure\", \"table\", \"sidewaystable\"]\n",
    "        if any([element in section.title for element in elements]):\n",
    "            text += f\"{section.title} caption: {section.abstract} \\n\"\n",
    "        else:\n",
    "            text += f\"{section.abstract} \\n\"\n",
    "    return await llm.acomplete(get_prompt(text))\n",
    "\n",
    "async def main(to_be_summarized):\n",
    "    tasks = [summarize(paper) for paper in to_be_summarized]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    for paper, result in zip(to_be_summarized, results):\n",
    "        paper.abstract = result.text\n",
    "\n",
    "def build_to_be_summarized(paper, to_be_summarized):\n",
    "    if paper.abstract is None:\n",
    "        can_be_summarized = True\n",
    "        for section in paper.sections:\n",
    "            if section.abstract is None:\n",
    "                can_be_summarized = False\n",
    "        \n",
    "        if can_be_summarized:\n",
    "            to_be_summarized.append(paper)\n",
    "\n",
    "    for section in paper.sections:\n",
    "        build_to_be_summarized(section, to_be_summarized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "235\n",
      "188\n",
      "143\n",
      "97\n",
      "53\n",
      "9\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "os.makedirs(dir_summarized_paper_trees, exist_ok=True)\n",
    "\n",
    "to_be_summarized = [None]\n",
    "while len(to_be_summarized) > 0:\n",
    "    to_be_summarized = []\n",
    "    for paper in papers:\n",
    "        build_to_be_summarized(paper, to_be_summarized)\n",
    "    print(len(to_be_summarized))\n",
    "    to_be_summarized = to_be_summarized[0:50]\n",
    "    asyncio.run(main(to_be_summarized))\n",
    "\n",
    "    for paper in papers:\n",
    "        with open(dir_summarized_paper_trees + paper.title[:-4] + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(paper, f)\n",
    "\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Summarize with bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_abstract = []\n",
    "def build_needs_abstract(paper, needs_abstract):\n",
    "    for section in paper.sections:\n",
    "        build_needs_abstract(section, needs_abstract)\n",
    "    if paper.abstract is None:\n",
    "        needs_abstract.append(paper)\n",
    "\n",
    "for paper in papers:\n",
    "    build_needs_abstract(paper, needs_abstract)\n",
    "\n",
    "len(needs_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer\n",
    "import math\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "MAX_SUMMARY_LENGTH = 300\n",
    "BART_MAX_TOKENS = 1024\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "# Function to split the text into chunks with overlap\n",
    "def split_into_chunks(text, max_length = BART_MAX_TOKENS - MAX_SUMMARY_LENGTH):\n",
    "    # Tokenize the text into tokens\n",
    "    tokens = tokenizer.encode(text, truncation=False)\n",
    "\n",
    "    # Calculate the ideal chunk size (as equal as possible)\n",
    "    chunk_size = math.ceil(len(tokens) / math.ceil(len(tokens) / max_length))\n",
    "\n",
    "    # Calculate how many chunks are needed\n",
    "    num_chunks = math.ceil(len(tokens) / chunk_size)\n",
    "\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "\n",
    "    for _ in range(num_chunks):\n",
    "        end_idx = start_idx + chunk_size\n",
    "        chunk = tokens[start_idx:end_idx]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        # Update start_idx for the next chunk\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # Decode chunks back to text\n",
    "    chunk_texts = [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n",
    "\n",
    "    return chunk_texts, len(tokens)\n",
    "\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 0/6149 [00:00<?, ?section/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2110.00831.tex --> Characterisation and results | Number of chunks: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Processing sections:   0%|          | 1/6149 [00:13<23:11:12, 13.58s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2110.00831.tex --> Mitigation strategies | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 2/6149 [00:14<10:12:59,  5.98s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2110.00831.tex --> Effects on the PID performance | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 3/6149 [00:14<5:58:38,  3.50s/section] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 1505.01654.tex --> Determination of signal yield | Number of chunks: 1\n",
      "Processing section: 2103.11058.tex --> Introduction | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 5/6149 [00:15<2:58:08,  1.74s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2103.11058.tex --> Signal modes and fit model | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 6/6149 [00:16<2:22:37,  1.39s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2309.05514.tex --> Analysis overview | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 7/6149 [00:16<1:58:11,  1.15s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2309.05514.tex --> Fit to determine the \\texorpdfstring{\\textbf{\\CP}}{CP} violation observables | Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 8/6149 [00:17<1:53:52,  1.11s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: 2309.05514.tex --> Appendix | Number of chunks: 1\n",
      "Processing section: 1403.1339.tex --> Introduction | Number of chunks: 1\n",
      "Processing section: 2201.03497.tex --> Headers | Number of chunks: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sections:   0%|          | 10/6149 [00:20<3:26:22,  2.02s/section]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for section in tqdm(needs_abstract, desc=\"Processing sections\", unit=\"section\"):\n",
    "    string = \"\"\n",
    "    for subsection in section.sections:\n",
    "        string += (subsection.abstract + \" \")\n",
    "        \n",
    "    chunked_string, num_tokens = split_into_chunks(string)\n",
    "    tqdm.write(f\"Processing section: {section} | Number of chunks: {len(chunked_string)}\")\n",
    "\n",
    "    # Excerpt is small enough that summarization is not needed.\n",
    "    if num_tokens < MAX_SUMMARY_LENGTH:\n",
    "        section.abstract = string\n",
    "    else:    \n",
    "        summaries = summarizer(chunked_string, max_length = max(MAX_SUMMARY_LENGTH // len(chunked_string), 100), min_length = 50)\n",
    "        section.abstract = \"\".join([summary['summary_text'] + \" \" for summary in summaries])\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        for paper in papers:\n",
    "            with open(dir_summarized_paper_trees + paper.title[:-4] + \".pkl\", \"wb\") as f:\n",
    "                pickle.dump(paper, f)\n",
    "        torch.cuda.empty_cache()\n",
    "        summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=\"cuda\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI7FJREFUeJzt3X1wVNXh//FPQsjyuBsTyC6pBGh9gMiDGjRsta2VSMT4VGNHHapRqY50sUIsBVoEpa1hsCOKRWitgh2lVDoFFUSMQWOVgBClBtSIiiYVNkGZZIHKBpLz+8Nf7rcLsbIkZE+y79fMzrD3nt2cc2dJ3nP3KcEYYwQAAGCRxFhPAAAA4GgECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALBOVIFy7733KiEhIeIydOhQZ/+hQ4cUCASUlpamPn36qKCgQLW1tRH3UV1drfz8fPXq1Uvp6emaNm2ajhw50j6rAQAAXUJStDc466yz9PLLL//fHST9311MnTpVa9eu1cqVK+XxeDR58mRdc801euONNyRJTU1Nys/Pl8/n08aNG7Vnzx7ddNNN6t69u+6///52WA4AAOgKEqL5ssB7771Xq1ev1rZt247Z19DQoP79+2v58uW69tprJUnvv/++hg0bpvLyco0ZM0br1q3T5Zdfrt27d8vr9UqSlixZounTp2vv3r1KTk5un1UBAIBOLeozKDt37lRGRoZ69Oghv9+v4uJiZWZmqqKiQocPH1Zubq4zdujQocrMzHQCpby8XCNGjHDiRJLy8vI0adIk7dixQ+ecc06rPzMcDiscDjvXm5ubtW/fPqWlpSkhISHaJQAAgBgwxmj//v3KyMhQYuL/fpVJVIGSk5OjZcuW6cwzz9SePXt033336Xvf+562b9+uYDCo5ORkpaSkRNzG6/UqGAxKkoLBYESctOxv2fd1iouLdd9990UzVQAAYKmamhqdeuqp/3NMVIEyfvx4598jR45UTk6OBg0apGeeeUY9e/Y8sVkeh5kzZ6qoqMi53tDQoMzMTNXU1Mjtdp+0nwucLMPnrI+4vv2+vBjNBAA6TigU0sCBA9W3b99vHBv1Uzz/LSUlRWeccYY+/PBDXXLJJWpsbFR9fX3EWZTa2lr5fD5Jks/n05tvvhlxHy3v8mkZ0xqXyyWXy3XMdrfbTaCgU0p09Yq4zuMYQDw5npdntOlzUA4cOKCPPvpIAwYMUHZ2trp3767S0lJnf1VVlaqrq+X3+yVJfr9flZWVqqurc8aUlJTI7XYrKyurLVMBAABdSFRnUH7xi1/oiiuu0KBBg7R7927NmTNH3bp10w033CCPx6OJEyeqqKhIqampcrvduvPOO+X3+zVmzBhJ0rhx45SVlaUbb7xR8+fPVzAY1KxZsxQIBFo9QwIAAOJTVIHy73//WzfccIO++OIL9e/fXxdeeKE2bdqk/v37S5IWLFigxMREFRQUKBwOKy8vT48++qhz+27dumnNmjWaNGmS/H6/evfurcLCQs2dO7d9VwUAADq1qD4HxRahUEgej0cNDQ08d49OafCMtRHXP5mXH6OZAEDHiebvN9/FAwAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOm0KlHnz5ikhIUFTpkxxth06dEiBQEBpaWnq06ePCgoKVFtbG3G76upq5efnq1evXkpPT9e0adN05MiRtkwFAAB0ISccKFu2bNEf//hHjRw5MmL71KlT9fzzz2vlypUqKyvT7t27dc011zj7m5qalJ+fr8bGRm3cuFFPPvmkli1bptmzZ5/4KgAAQJdyQoFy4MABTZgwQY899phOOeUUZ3tDQ4Mef/xxPfjgg7r44ouVnZ2tpUuXauPGjdq0aZMk6aWXXtK7776rp556SmeffbbGjx+v3/zmN1q0aJEaGxvbZ1UAAKBTO6FACQQCys/PV25ubsT2iooKHT58OGL70KFDlZmZqfLycklSeXm5RowYIa/X64zJy8tTKBTSjh07Wv154XBYoVAo4gIAALqupGhvsGLFCr311lvasmXLMfuCwaCSk5OVkpISsd3r9SoYDDpj/jtOWva37GtNcXGx7rvvvminCgAAOqmozqDU1NTorrvu0tNPP60ePXqcrDkdY+bMmWpoaHAuNTU1HfazAQBAx4sqUCoqKlRXV6dzzz1XSUlJSkpKUllZmRYuXKikpCR5vV41Njaqvr4+4na1tbXy+XySJJ/Pd8y7elqut4w5msvlktvtjrgAAICuK6pAGTt2rCorK7Vt2zbnMnr0aE2YMMH5d/fu3VVaWurcpqqqStXV1fL7/ZIkv9+vyspK1dXVOWNKSkrkdruVlZXVTssCAACdWVSvQenbt6+GDx8esa13795KS0tztk+cOFFFRUVKTU2V2+3WnXfeKb/frzFjxkiSxo0bp6ysLN14442aP3++gsGgZs2apUAgIJfL1U7LAgAAnVnUL5L9JgsWLFBiYqIKCgoUDoeVl5enRx991NnfrVs3rVmzRpMmTZLf71fv3r1VWFiouXPntvdUAABAJ5VgjDGxnkS0QqGQPB6PGhoaeD0KOqXBM9ZGXP9kXn6MZgIAHSeav998Fw8AALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOtEFSiLFy/WyJEj5Xa75Xa75ff7tW7dOmf/oUOHFAgElJaWpj59+qigoEC1tbUR91FdXa38/Hz16tVL6enpmjZtmo4cOdI+qwEAAF1CVIFy6qmnat68eaqoqNDWrVt18cUX66qrrtKOHTskSVOnTtXzzz+vlStXqqysTLt379Y111zj3L6pqUn5+flqbGzUxo0b9eSTT2rZsmWaPXt2+64KAAB0agnGGNOWO0hNTdUDDzyga6+9Vv3799fy5ct17bXXSpLef/99DRs2TOXl5RozZozWrVunyy+/XLt375bX65UkLVmyRNOnT9fevXuVnJx8XD8zFArJ4/GooaFBbre7LdMHYmLwjLUR1z+Zlx+jmQBAx4nm7/cJvwalqalJK1as0MGDB+X3+1VRUaHDhw8rNzfXGTN06FBlZmaqvLxcklReXq4RI0Y4cSJJeXl5CoVCzlmY1oTDYYVCoYgLAADouqIOlMrKSvXp00cul0t33HGHVq1apaysLAWDQSUnJyslJSVivNfrVTAYlCQFg8GIOGnZ37Lv6xQXF8vj8TiXgQMHRjttAADQiUQdKGeeeaa2bdumzZs3a9KkSSosLNS77757MubmmDlzphoaGpxLTU3NSf15AAAgtpKivUFycrJOO+00SVJ2dra2bNmihx9+WNddd50aGxtVX18fcRaltrZWPp9PkuTz+fTmm29G3F/Lu3xaxrTG5XLJ5XJFO1UAANBJtflzUJqbmxUOh5Wdna3u3burtLTU2VdVVaXq6mr5/X5Jkt/vV2Vlperq6pwxJSUlcrvdysrKautUAABAFxHVGZSZM2dq/PjxyszM1P79+7V8+XK9+uqrWr9+vTwejyZOnKiioiKlpqbK7XbrzjvvlN/v15gxYyRJ48aNU1ZWlm688UbNnz9fwWBQs2bNUiAQ4AwJAABwRBUodXV1uummm7Rnzx55PB6NHDlS69ev1yWXXCJJWrBggRITE1VQUKBwOKy8vDw9+uijzu27deumNWvWaNKkSfL7/erdu7cKCws1d+7c9l0VAADo1Nr8OSixwOegoLPjc1AAxKMO+RwUAACAk4VAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYJ2ovs0YiHd8yR8AdAzOoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDpRBUpxcbHOO+889e3bV+np6br66qtVVVUVMebQoUMKBAJKS0tTnz59VFBQoNra2ogx1dXVys/PV69evZSenq5p06bpyJEjbV8NAADoEqIKlLKyMgUCAW3atEklJSU6fPiwxo0bp4MHDzpjpk6dqueff14rV65UWVmZdu/erWuuucbZ39TUpPz8fDU2Nmrjxo168skntWzZMs2ePbv9VgUAADq1BGOMOdEb7927V+np6SorK9P3v/99NTQ0qH///lq+fLmuvfZaSdL777+vYcOGqby8XGPGjNG6det0+eWXa/fu3fJ6vZKkJUuWaPr06dq7d6+Sk5OP+TnhcFjhcNi5HgqFNHDgQDU0NMjtdp/o9IGoDZ6xNuL6J/PyY3o/ANCZhEIheTye4/r73abXoDQ0NEiSUlNTJUkVFRU6fPiwcnNznTFDhw5VZmamysvLJUnl5eUaMWKEEyeSlJeXp1AopB07drT6c4qLi+XxeJzLwIED2zJtAABguRMOlObmZk2ZMkUXXHCBhg8fLkkKBoNKTk5WSkpKxFiv16tgMOiM+e84adnfsq81M2fOVENDg3Opqak50WkDAIBOIOlEbxgIBLR9+3a9/vrr7TmfVrlcLrlcrpP+cwAAgB1O6AzK5MmTtWbNGr3yyis69dRTne0+n0+NjY2qr6+PGF9bWyufz+eMOfpdPS3XW8YAAID4FlWgGGM0efJkrVq1Shs2bNCQIUMi9mdnZ6t79+4qLS11tlVVVam6ulp+v1+S5Pf7VVlZqbq6OmdMSUmJ3G63srKy2rIWAADQRUT1FE8gENDy5cv17LPPqm/fvs5rRjwej3r27CmPx6OJEyeqqKhIqampcrvduvPOO+X3+zVmzBhJ0rhx45SVlaUbb7xR8+fPVzAY1KxZsxQIBHgaBwAASIoyUBYvXixJuuiiiyK2L126VDfffLMkacGCBUpMTFRBQYHC4bDy8vL06KOPOmO7deumNWvWaNKkSfL7/erdu7cKCws1d+7ctq0EAAB0GVEFyvF8ZEqPHj20aNEiLVq06GvHDBo0SC+88EI0PxoAAMQRvosHAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYJ2kWE8gngyesfaYbZ/My4/BTAAAsBtnUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgnagD5bXXXtMVV1yhjIwMJSQkaPXq1RH7jTGaPXu2BgwYoJ49eyo3N1c7d+6MGLNv3z5NmDBBbrdbKSkpmjhxog4cONCmhQAAgK4j6kA5ePCgRo0apUWLFrW6f/78+Vq4cKGWLFmizZs3q3fv3srLy9OhQ4ecMRMmTNCOHTtUUlKiNWvW6LXXXtPtt99+4qsAAABdStQf1DZ+/HiNHz++1X3GGD300EOaNWuWrrrqKknSX/7yF3m9Xq1evVrXX3+93nvvPb344ovasmWLRo8eLUl65JFHdNlll+n3v/+9MjIyjrnfcDiscDjsXA+FQtFOGwAAdCLt+hqUXbt2KRgMKjc319nm8XiUk5Oj8vJySVJ5eblSUlKcOJGk3NxcJSYmavPmza3eb3FxsTwej3MZOHBge04bAABYpl0DJRgMSpK8Xm/Edq/X6+wLBoNKT0+P2J+UlKTU1FRnzNFmzpyphoYG51JTU9Oe0wYAAJbpFN/F43K55HK5Yj0NAADQQdr1DIrP55Mk1dbWRmyvra119vl8PtXV1UXsP3LkiPbt2+eMAQAA8a1dA2XIkCHy+XwqLS11toVCIW3evFl+v1+S5Pf7VV9fr4qKCmfMhg0b1NzcrJycnPacDgAA6KSifornwIED+vDDD53ru3bt0rZt25SamqrMzExNmTJFv/3tb3X66adryJAhuueee5SRkaGrr75akjRs2DBdeumluu2227RkyRIdPnxYkydP1vXXX9/qO3gAAED8iTpQtm7dqh/+8IfO9aKiIklSYWGhli1bpl/+8pc6ePCgbr/9dtXX1+vCCy/Uiy++qB49eji3efrppzV58mSNHTtWiYmJKigo0MKFC9thOQAAoCuIOlAuuugiGWO+dn9CQoLmzp2ruXPnfu2Y1NRULV++PNofDQAA4gTfxQMAAKzTKd5mHE8Gz1h7zLZP5uXHYCYAAMQOgXIStRYbJzLmeG5DxAAAuhKe4gEAANYhUAAAgHV4iqeLOJ6ningaCADQWRAoncCJvE4FAIDOjKd4AACAdQgUAABgHQIFAABYh0ABAADW4UWy7YQXsgIA0H44gwIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArMO7eNBmrb2Die/9AQC0BWdQAACAdQgUAABgHZ7iwf9k29M3ts0HAHBycAYFAABYh0ABAADW4SmeOMb3BwEAbMUZFAAAYB0CBQAAWIdAAQAA1uE1KHGE15wAADoLzqAAAADrcAblOPDhYNE7+pi1dryOZwwAID5xBgUAAFiHQAEAANbhKR5Y40SfSuOpIgDoejiDAgAArMMZFOD/40wMANiDQEHUOvLzVPjsFgCITzzFAwAArMMZFMQFzsQAQOdCoJwg/uDhePFYAYDoESjoEPyRBgBEg0AB2hkxBgBtR6AAX4PQAIDYIVBawR8mAABii0BBl8PntABA58fnoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOkmxngCA9jN4xtpjtn0yLz8GMwGAtolpoCxatEgPPPCAgsGgRo0apUceeUTnn39+LKcEdDntFS3Hcz8n+rOOvh1RBSBmgfK3v/1NRUVFWrJkiXJycvTQQw8pLy9PVVVVSk9Pj9W0gJho7Q/70U7mH+2TeeblROKjM54J6oxzBmwWs0B58MEHddttt+mWW26RJC1ZskRr167VE088oRkzZkSMDYfDCofDzvWGhgZJUigUOilzaw7/56TcL9AWmVNXduh9Hf3/q7X/Fycyp9b+3x7P/7n2+v8+fM76bxyz/b68qO/3eI5Pa/d7suYDRKO1x+HJeNy1/D82xnzzYBMD4XDYdOvWzaxatSpi+0033WSuvPLKY8bPmTPHSOLChQsXLly4dIFLTU3NN7ZCTM6gfP7552pqapLX643Y7vV69f777x8zfubMmSoqKnKuNzc3a9++fUpLS1NCQkLUPz8UCmngwIGqqamR2+2OfgFdAMeAYyBxDCSOgcQxiPf1Sx13DIwx2r9/vzIyMr5xbKd4F4/L5ZLL5YrYlpKS0ub7dbvdcftgbMEx4BhIHAOJYyBxDOJ9/VLHHAOPx3Nc42LyOSj9+vVTt27dVFtbG7G9trZWPp8vFlMCAAAWiUmgJCcnKzs7W6Wlpc625uZmlZaWyu/3x2JKAADAIjF7iqeoqEiFhYUaPXq0zj//fD300EM6ePCg866ek8nlcmnOnDnHPG0UTzgGHAOJYyBxDCSOQbyvX7LzGCQYczzv9Tk5/vCHPzgf1Hb22Wdr4cKFysnJidV0AACAJWIaKAAAAK3hywIBAIB1CBQAAGAdAgUAAFiHQAEAANaJy0BZtGiRBg8erB49eignJ0dvvvlmrKfULl577TVdccUVysjIUEJCglavXh2x3xij2bNna8CAAerZs6dyc3O1c+fOiDH79u3ThAkT5Ha7lZKSookTJ+rAgQMduIq2KS4u1nnnnae+ffsqPT1dV199taqqqiLGHDp0SIFAQGlpaerTp48KCgqO+dDA6upq5efnq1evXkpPT9e0adN05MiRjlzKCVu8eLFGjhzpfCKk3+/XunXrnP1dff1HmzdvnhISEjRlyhRnW1c/Bvfee68SEhIiLkOHDnX2d/X1t/jss8/0k5/8RGlpaerZs6dGjBihrVu3Ovu7+u/EwYMHH/M4SEhIUCAQkNQJHgdt/ua/TmbFihUmOTnZPPHEE2bHjh3mtttuMykpKaa2tjbWU2uzF154wfz61782//jHP4ykY76Mcd68ecbj8ZjVq1ebf/3rX+bKK680Q4YMMV9++aUz5tJLLzWjRo0ymzZtMv/85z/NaaedZm644YYOXsmJy8vLM0uXLjXbt28327ZtM5dddpnJzMw0Bw4ccMbccccdZuDAgaa0tNRs3brVjBkzxnz3u9919h85csQMHz7c5Obmmrffftu88MILpl+/fmbmzJmxWFLUnnvuObN27VrzwQcfmKqqKvOrX/3KdO/e3Wzfvt0Y0/XX/9/efPNNM3jwYDNy5Ehz1113Odu7+jGYM2eOOeuss8yePXucy969e539XX39xhizb98+M2jQIHPzzTebzZs3m48//tisX7/efPjhh86Yrv47sa6uLuIxUFJSYiSZV155xRhj/+Mg7gLl/PPPN4FAwLne1NRkMjIyTHFxcQxn1f6ODpTm5mbj8/nMAw884Gyrr683LpfL/PWvfzXGGPPuu+8aSWbLli3OmHXr1pmEhATz2Wefddjc21NdXZ2RZMrKyowxX625e/fuZuXKlc6Y9957z0gy5eXlxpivQi8xMdEEg0FnzOLFi43b7TbhcLhjF9BOTjnlFPPnP/85rta/f/9+c/rpp5uSkhLzgx/8wAmUeDgGc+bMMaNGjWp1Xzys3xhjpk+fbi688MKv3R+PvxPvuusu853vfMc0Nzd3isdBXD3F09jYqIqKCuXm5jrbEhMTlZubq/Ly8hjO7OTbtWuXgsFgxNo9Ho9ycnKctZeXlyslJUWjR492xuTm5ioxMVGbN2/u8Dm3h4aGBklSamqqJKmiokKHDx+OOA5Dhw5VZmZmxHEYMWJExLdt5+XlKRQKaceOHR04+7ZramrSihUrdPDgQfn9/rhafyAQUH5+fsRapfh5DOzcuVMZGRn69re/rQkTJqi6ulpS/Kz/ueee0+jRo/XjH/9Y6enpOuecc/TYY485++Ptd2JjY6Oeeuop3XrrrUpISOgUj4O4CpTPP/9cTU1NEQdbkrxer4LBYIxm1TFa1ve/1h4MBpWenh6xPykpSampqZ3y+DQ3N2vKlCm64IILNHz4cElfrTE5OfmYb8M++ji0dpxa9nUGlZWV6tOnj1wul+644w6tWrVKWVlZcbP+FStW6K233lJxcfEx++LhGOTk5GjZsmV68cUXtXjxYu3atUvf+973tH///rhYvyR9/PHHWrx4sU4//XStX79ekyZN0s9//nM9+eSTkuLvd+Lq1atVX1+vm2++WVLn+H8Qs+/iAU62QCCg7du36/XXX4/1VDrcmWeeqW3btqmhoUF///vfVVhYqLKyslhPq0PU1NTorrvuUklJiXr06BHr6cTE+PHjnX+PHDlSOTk5GjRokJ555hn17NkzhjPrOM3NzRo9erTuv/9+SdI555yj7du3a8mSJSosLIzx7Dre448/rvHjxysjIyPWUzlucXUGpV+/furWrdsxr1Kura2Vz+eL0aw6Rsv6/tfafT6f6urqIvYfOXJE+/bt63THZ/LkyVqzZo1eeeUVnXrqqc52n8+nxsZG1dfXR4w/+ji0dpxa9nUGycnJOu2005Sdna3i4mKNGjVKDz/8cFysv6KiQnV1dTr33HOVlJSkpKQklZWVaeHChUpKSpLX6+3yx+BoKSkpOuOMM/Thhx/GxWNAkgYMGKCsrKyIbcOGDXOe6oqn34mffvqpXn75Zf30pz91tnWGx0FcBUpycrKys7NVWlrqbGtublZpaan8fn8MZ3byDRkyRD6fL2LtoVBImzdvdtbu9/tVX1+viooKZ8yGDRvU3Nzcab7E0RijyZMna9WqVdqwYYOGDBkSsT87O1vdu3ePOA5VVVWqrq6OOA6VlZURv5hKSkrkdruP+YXXWTQ3NyscDsfF+seOHavKykpt27bNuYwePVoTJkxw/t3Vj8HRDhw4oI8++kgDBgyIi8eAJF1wwQXHfMTABx98oEGDBkmKn9+JkrR06VKlp6crPz/f2dYpHgcn/WW4llmxYoVxuVxm2bJl5t133zW33367SUlJiXiVcme1f/9+8/bbb5u3337bSDIPPvigefvtt82nn35qjPnqLXUpKSnm2WefNe+884656qqrWn1L3TnnnGM2b95sXn/9dXP66ad3mrfUGWPMpEmTjMfjMa+++mrE2+v+85//OGPuuOMOk5mZaTZs2GC2bt1q/H6/8fv9zv6Wt9aNGzfObNu2zbz44oumf//+neYtljNmzDBlZWVm165d5p133jEzZswwCQkJ5qWXXjLGdP31t+a/38VjTNc/Bnfffbd59dVXza5du8wbb7xhcnNzTb9+/UxdXZ0xpuuv35iv3mKelJRkfve735mdO3eap59+2vTq1cs89dRTzph4+J3Y1NRkMjMzzfTp04/ZZ/vjIO4CxRhjHnnkEZOZmWmSk5PN+eefbzZt2hTrKbWLV155xUg65lJYWGiM+eptdffcc4/xer3G5XKZsWPHmqqqqoj7+OKLL8wNN9xg+vTpY9xut7nlllvM/v37Y7CaE9Pa+iWZpUuXOmO+/PJL87Of/cyccsopplevXuZHP/qR2bNnT8T9fPLJJ2b8+PGmZ8+epl+/fubuu+82hw8f7uDVnJhbb73VDBo0yCQnJ5v+/fubsWPHOnFiTNdff2uODpSufgyuu+46M2DAAJOcnGy+9a1vmeuuuy7i8z+6+vpbPP/882b48OHG5XKZoUOHmj/96U8R++Phd+L69euNpGPWZYz9j4MEY4w5+edpAAAAjl9cvQYFAAB0DgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArPP/AIZewBca9aNBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ab_len = []\n",
    "ab_section = []\n",
    "\n",
    "def build_ab_len(paper):\n",
    "    for section in paper.sections:\n",
    "        build_ab_len(section)\n",
    "    if paper.abstract is not None:\n",
    "        ab = paper.abstract\n",
    "        ab_len.append(len(tokenizer.encode(ab, truncation=False)))\n",
    "        ab_section.append(paper)\n",
    "\n",
    "for i, paper in enumerate(papers):\n",
    "    build_ab_len(paper)\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ab_len, bins = 100)\n",
    "plt.ylim(0, 500)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Chunk Length (chars): 2115\n",
      "Section: 2412.09414.tex --> Headers --> Chunk 11 \n",
      " Text:  used to correct the five-dimensional decay model of the corresponding dielectron mode.\n",
      "In addition, particle-identification, hardware-trigger, and tracking efficiencies as well as the dielectron-mass resolution are corrected using dedicated control channels in data. \n",
      "Systematic uncertainties related to the determination of the yields arise due to limited knowledge of the various fit components and are evaluated using pseudoexperiments, where alternative fit models are tested. These include variations of the signal and background shape parameters within the uncertainties determined from the fits to simulation, and a signal shape obtained with a modified electron momentum resolution. In addition, a Bukin distribution is tested as an alternative distribution to represent the signal. Since not all selection criteria can be applied to background simulation because of limited simulated sample sizes, the misidentified background shapes are recomputed using an alternative set of selection criteria. The combinatorial background shape is determined in alternative \\dm ranges.  \n",
      "The fraction of signal decays migrating into other regions of dielectron mass is varied within its uncertainty. Furthermore, fit components are re-evaluated using simulated samples corresponding to different data-taking years. The dominant systematic uncertainty arising from assumptions in the fit is determined by fully neglecting all partially reconstructed backgrounds. The impact of neglecting further misidentified backgrounds is found to be negligible everywhere except in the signal $\\rho^0/\\omega$ dielectron-mass region, where a contribution from \\Dkpeenr decays misreconstructed as the signal are found, and the appropriate systematic uncertainty is computed. \n",
      "The statistical uncertainty on the normalization yield leads to a relative systematic uncertainty of $4.8\\%$ ($4.5\\%$) for \\Dppee (\\Dkkee). \n",
      "Systematic uncertainties affecting the efficiency ratio include residual data-simulation differences and limitations in the data-driven methods used to determine the particle-identification, tracking and trigger effic\n",
      "\n",
      "\n",
      "\n",
      "Min Chunk Length (chars): 18\n",
      "Section: 2304.14891.tex --> Dalitz plot analysis of the \\boldmath{\\etac} decay to \\boldmath{\\kskpi} --> Headers \n",
      " Text: \n",
      "\\label{sec:etac}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Chunk Length (chars): {max(ab_len)}\")\n",
    "max_sec_idx = ab_len.index(max(ab_len))\n",
    "max_sec = ab_section[max_sec_idx]\n",
    "max_sec_id = max_sec.title\n",
    "parent = max_sec.parent\n",
    "while parent is not None:\n",
    "    max_sec_id = f\"{parent.title} --> {max_sec_id}\"\n",
    "    parent = parent.parent\n",
    "print(f\"Section: {max_sec_id} \\n Text: {max_sec.abstract}\")\n",
    "\n",
    "ab_len.pop(max_sec_idx)\n",
    "ab_section.pop(max_sec_idx)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"Min Chunk Length (chars): {min(ab_len)}\")\n",
    "min_sec_idx = ab_len.index(min(ab_len))\n",
    "min_sec = ab_section[min_sec_idx]\n",
    "min_sec_id = min_sec.title\n",
    "parent = min_sec.parent\n",
    "while parent is not None:\n",
    "    min_sec_id = f\"{parent.title} --> {min_sec_id}\"\n",
    "    parent = parent.parent\n",
    "print(f\"Section: {min_sec_id} \\n Text: {min_sec.abstract}\")\n",
    "\n",
    "ab_len.pop(min_sec_idx)\n",
    "ab_section.pop(min_sec_idx)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beauty-in-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
