{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Algorithm for LaTeX Corpus to Tree Database for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "class Paper:\n",
    "    def __init__(self, title: str, text: str, abstract: str = None, parent = None, depth: int = 0):\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.text = text\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.depth = depth\n",
    "\n",
    "        self.sections = self.split_to_sections(self.text)\n",
    "        if len(self.sections) > 0 and self.abstract is None:\n",
    "            self.abstract = self.generate_abstract()\n",
    "\n",
    "    def __repr__(self):\n",
    "        string = \"\"\n",
    "        if self.depth > 0:\n",
    "            string += \"--\"*(self.depth) + \">\"\n",
    "        string += self.title + \"\\n\"\n",
    "        for section in self.sections:\n",
    "            string += section.__repr__()\n",
    "        return string\n",
    "\n",
    "    def split_to_sections(self, text: str):\n",
    "        pattern = r\"(\\\\\" + \"sub\" * self.depth + r\"section\\s*({(?:[^{}]*+|(?2))*}))\"\n",
    "        matches = re.finditer(pattern, text)\n",
    "        try:       \n",
    "            sections = []\n",
    "            start, title = 0, \"Headers\"\n",
    "            for match in matches:\n",
    "                end = match.start()\n",
    "                section_text = text[start : end]\n",
    "                if section_text.strip() == \"\":\n",
    "                    continue\n",
    "                sections.append(Paper(title = title, text = section_text, abstract = None, parent = self, depth = self.depth + 1))\n",
    "                start, title = match.end(), match.group(2)[1:-1]\n",
    "        except :\n",
    "            sections = []\n",
    "        return sections\n",
    "        \n",
    "    def generate_abstract(self):\n",
    "        parent = self.parent\n",
    "        abstract = \"\"\n",
    "        while parent:\n",
    "            abstract = parent.abstract + abstract\n",
    "            parent = parent.parent\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        ======== Problem Statement ========\n",
    "        You are an elite particle physics researcher. You will be given the abstract for a particle physics paper as well as a text excerpt from that paper. Your job is to, in as few words as possible, add on to the existing abstract a fully descriptive description of specifically the contents of the text excerpt. You may not modify the original abstract, and your output should start where the abstract ends.\n",
    "\n",
    "        ======== Abstract =================\n",
    "        {abstract}\n",
    "\n",
    "        ======== Text Excerpt =============\n",
    "        {self.text}\n",
    "        \"\"\"\n",
    "\n",
    "        message = HumanMessage(content=prompt)\n",
    "        response = llm(messages=[prompt])\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "\n",
    "dir_expanded_tex = \"../data/expanded_tex_nomacro/\"\n",
    "dir_abstracts = \"../data/abstracts/\"\n",
    "i = 0\n",
    "for filename in os.listdir(dir_expanded_tex):\n",
    "    with open(dir_abstracts + filename) as file:\n",
    "        abstract = file.read()\n",
    "    with open(dir_expanded_tex + filename) as file:\n",
    "        full_tex = file.read()\n",
    "\n",
    "    papers.append(Paper(filename, full_tex, abstract = abstract))\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1304.4518.tex\n",
       "-->Headers\n",
       "-->Introduction\n",
       "-->Detector and triggers\n",
       "-->Signal candidate selection\n",
       "-->Signal and background discrimination\n",
       "-->Normalisation\n",
       "-->Background studies"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509.00414.tex\n",
       "-->Headers\n",
       "-->Introduction\n",
       "-->Detector and simulation\n",
       "-->Event selection\n",
       "-->Event yields\n",
       "-->Results\n",
       "---->Headers\n",
       "---->Differential branching fraction\n",
       "---->CKM matrix elements"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1304.4530.tex\n",
       "-->Headers\n",
       "-->Introduction\n",
       "-->\\mbox{LHCb} detector\n",
       "-->Event selection\n",
       "-->Observation of {\\boldmath\\B_c^+{}\\rightarrow{}{J\\mskip -3mu/\\mskip -2mu\\psi\\mskip 2mu}{}D^+_s}\n",
       "-->Normalization to the {\\boldmath\\B_c^+{}\\rightarrow{}{J\\mskip -3mu/\\mskip -2mu\\psi\\mskip 2mu}{}\\pi^+} decay mode\n",
       "-->Systematic uncertainties"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first measurement of ${C\\\\!P}$ asymmetries in the decay ${B_s^0\\\\to J/\\\\psi \\\\overline{K}^{*}(892)^{0}}$ and an updated measurement of its branching fraction and polarisation fractions are presented. The results are obtained using data corresponding to an integrated luminosity of $3.0\\\\,fb^{-1}$ of proton-proton collisions recorded with the LHCb detector at centre-of-mass energies of $7$ and $8\\\\,\\\\mathrm{TeV}$. Together with constraints from ${B^0\\\\to J/\\\\psi \\\\rho^0}$, the results are used to constrain additional contributions due to penguin diagrams in the ${C\\\\!P}$-violating phase ${{\\\\phi}_{s}}$, measured through ${B_s^0}$ decays to charmonium.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[2].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The branching fraction of the decay ${B_s^0\\\\to J/\\\\psi K^{*}(892)^{0}}$ is determined by normalising to the decay channels ${B_s^0\\\\to J/\\\\psi \\\\phi}$ and ${B^0\\\\to J/\\\\psi K^{*}}$, with detailed calculations of efficiency ratios and correction factors to account for background interference and angular acceptance. The results yield a branching fraction ratio of ${\\\\BRof\\\\BsJpsiKst/\\\\BRof\\\\BsJpsiPhi = (4.05 \\\\pm 0.19 \\\\, \\\\text{(stat)} \\\\pm 0.13 \\\\, \\\\text{(syst)})\\\\%}$ and ${\\\\BRof\\\\BsJpsiKst/\\\\BRof\\\\BdJpsiKst = (2.99 \\\\pm 0.14 \\\\, \\\\text{(stat)} \\\\pm 0.12 \\\\, \\\\text{(syst)} \\\\pm 0.17 \\\\, (f_d/f_s))\\\\%}$. The final averaged branching fraction is found to be ${\\\\BR{\\\\BsJpsiKst} = (4.14 \\\\pm 0.18 \\\\, \\\\text{(stat)} \\\\pm 0.26 \\\\, \\\\text{(syst)} \\\\pm 0.24 \\\\, (f_d/f_s))\\\\times 10^{-5}}$, consistent with previous measurements.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[2].sections[7].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = papers[3].abstract\n",
    "text = papers[3].sections[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analysis employs stringent selection criteria for charged particle tracks, utilizing a neural network to enhance track quality and suppress fake tracks. Duplicate particles are minimized through the Kullback-Leibler divergence, while muon and hadron candidates are identified based on likelihood ratios and momentum requirements. The selection of J/ψ candidates is based on oppositely-charged muon pairs, ensuring good vertex quality and separation from the primary interaction vertex. D_s mesons are reconstructed with specific mass and momentum criteria, and B_c candidates are formed from J/ψD_s pairs, subjected to kinematic fitting and decay time requirements to ensure accurate measurements.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decays $B^+_c \\rightarrow J/\\psi D_s^+$ and $B^+_c \\rightarrow J/\\psi D_s^{*+}$ are observed for the first time using a dataset, corresponding to an integrated luminosity of 3$fb^{-1}$, collected by the LHCb experiment in proton-proton collisions at centre-of-mass energies of $\\sqrt{s}$=7 and 8 TeV. The statistical significance for both signals is in excess of 9 standard deviations. The following ratios of branching fractions are measured to be $BR(B^+_c \\rightarrow J/\\psi D_s^+)/BR(B^+_c \\rightarrow J/\\psi \\pi+) = 2.90 \\pm 0.57 \\pm 0.24$, $BR(B^+_c \\rightarrow J/\\psi D_s^{*+}) / BR (B^+_c \\rightarrow J/\\psi D_s^+) = 2.37 \\pm 0.56 \\pm 0.10$, where the first uncertainties are statistical and the second systematic. The mass of the \\Bc meson is measured to be $m_{B^+_c} = 6276.28 \\pm 1.44 (stat) \\pm 0.36(syst) MeV/c^2$, using the $B^+_c \\rightarrow J/\\psi D_s^+$ decay mode.\n",
      "The analysis employs stringent selection criteria for charged particle tracks, utilizing a neural network to enhance track quality and suppress fake tracks. Duplicate particles are minimized through the Kullback-Leibler divergence, while muon and hadron candidates are identified based on likelihood ratios and momentum requirements. The selection of J/ψ candidates is based on oppositely-charged muon pairs, ensuring good vertex quality and separation from the primary interaction vertex. D_s mesons are reconstructed with specific mass and momentum criteria, and B_c candidates are formed from J/ψD_s pairs, subjected to kinematic fitting and decay time requirements to ensure accurate measurements.\n"
     ]
    }
   ],
   "source": [
    "print(abstract + \"\\n\" + response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
